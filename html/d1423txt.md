
### Reinforcement Learning With Q-Learning

hello everyone and welcome to the next module in this course on reinforcement learning so what we're gonna be doing in this module is talking about another technique in machine learning called reinforcement learning now if you remember at the very beginning of this course which I know. For you guys is probably at like six hours ago at this point we did briefly discuss what reinforcement learning was now I'll go through a recap here just to make sure everyone's clear on it but essentially reinforcement learning is kind of the strategy and machine learning. 
Where rather than feeding a ton of data and a ton of examples to our model we let the model or in this case we're gonna call it agent actually come up with these examples itself and we do this by letting an agent explore an environment now. Essentially the concept here is just like humans the way that we learned to do something say like play a game is by actually doing it we get put in the environment we try to do it and then you know we'll make mistakes.

Where rather than feeding a ton of data and a ton of examples to our model we let the model or in this case we're gonna call it agent actually come up with these examples itself and we do this by letting an agent explore an environment now. Essentially the concept here is just like humans the way that we learned to do something say like play a game is by actually doing it we get put in the environment we try to do it and then you know we'll make mistakes.

 We'll encounter different things we'll see what goes correctly and based on those experiences we learn and we figure out the correct things to do a very basic example is you know say we play a game and when we go left. We fell off a cliff or something right next time we play that game and we get to that point we're probably not going to go left because we're gonna remember the fact that that was bad and hence learned from our mistakes. So that's kind of the idea here with reinforcement learning I'm gonna go through exactly how this works and gives some better examples and some math behind one of the implementations we're gonna use. But I just want to make this clear that there's a lot of different types of reinforcement learning. 

In this example we're just gonna be talking about something called cue learning and I'm gonna keep this module shorter compared to the other ones because this field of AI and machine learning is pretty complex and can get pretty difficult pretty quickly so it's something that's maybe a more advanced topic for some of you guys. Alright so anyways now we need to define some terminology before I could even start really explaining the technique we're gonna use and how this works so we have something called an environment agent state action and reward now I'm hoping that some of you guys. 

environment. So if we're thinking about reinforcement learning when it to say training in AI to play a game well in that instance they we're talking about Mario the agent would be Mario as that is the thing that's moving around. And exploring our environment and the environment would be the level in which we're playing in so you know in another example maybe in the example we're gonna use below we're actually gonna be kind of in almost a maze. 

Will remember this from the very beginning but environment is essentially what we're trying to solve or what we're trying to do so in reinforcement learning we have this notion of an agent and the agent is what's going to explore. The So the environment is gonna be the maze and the agent is going to be the character or the entity or whatever you want to call it that's exploring that maze so it's pretty it's usually pretty intuitive to come up with what the environment. And the agent are although in some more complex examples it might not always be clear but just understand that reinforcement learning deals with an agent something exploring an environment and a very common application of reinforcement learning is in training a eyes on how to play games. 

And it's actually very interesting what they've been able to do in that field recently okay so we have environments an agent hopefully that makes sense the next thing to talk about is state so essentially the state is where you are in the environment so obviously inside of the environment. We can have many different states and a state could also be associated with the you know agent itself so we're gonna say the agent is in a specific state whenever it is in some part of the environment now in the case of our game the state. That an agent would be in would be their position in the level say if they're at you know X Y coordinates like 10 20 they would be at state or in state 10 20 that's kind of how we think about States now obviously state can be applied in some different instances. 

As well we're playing say maybe a turn-based game you know actually that's not really a great example. I'm trying to think of something where the state wouldn't necessarily be a position maybe if you're playing a game where you have like health or something like that. And part of the state might be the health of the character this can get complicated depending on what you're trying to do but just understand the notion that for most of our examples state is simply gonna be location although it really is just kind of telling us information about where the agent is and its status in the environment. 

So next we have this notion of an action so in reinforcement learning our agent is exploring the environments it's trying to figure out the best way or how to accomplish some kind of goal in the environment. And the way that it interacts with the environment is with something called actions. Now actions could be say moving the left arrow key right moving to the left and the environment moving to the right it could be something like jumping and an action can actually be not doing something at all so when we say you know agent performed action that could really mean that the action and that may be time step was that they didn't do something right that they didn't do anything that was their action. 

So that's kind of the idea of action in the example of our Mario one which I keep going back to an action would be something like jumping and typically actions will change the state of our entity. Or our agent although they might not necessarily do that in fact we will observe with a lot of the different actions that we could actually be in the same state after performing that action. All right so now we're on to the last part which is actually the most important to understand and this is reward so reward is actually what our agent is trying to maximize weld is in the environment so the goal of reinforcement learning is to have this. 

Agent navigate this environment go through a bunch of the different states of it and determine which actions maximize the reward at every given state so essentially the goal of our agent is to maximize our reward. But what is a reward. Well after every action that's taken the agent will receive a reward now this reward is something that us as the programmer needs to come up with the reason we need to do this is because we need to tell the agent when it's performing well and when it's performing poorly. And just like we had like a loss function in neural networks when we were using those before this is almost like our loss function you know the higher this number is the more reward that an agent gets the better the lower the reward. 

You know it's not as good it's not doing as well so that's how we kind of monitor and assess performance for our agents is by determining the almost average amount of reward that they're able to achieve and their goal is really to you know it's almost an optimization problem where they're trying to maximize this reward. So what we're gonna do in reinforcement learning is have this agent exploring the environment going through these different states and performing these different actions trying to maximize its reward and obviously if we're trying to get the agent to say finish a level or you know complete the game then the maximum maximum reward will be achieved once it's completed the level or completed the game. 

And if it does things that we don't like say like dying or like jumping in the wrong spot we could give it a negative reward to try to influence it to not do that and our goal you know when we train these agents is for them to get the most reward. And we hope that they're gonna learn the optimal route through a level or through some environment that will maximize that reward for them okay so now I'm gonna talk about a take technique called cue learning which is actually just an algorithm that we're gonna use to implement this idea of reinforcement learning. 

We're not gonna get into anything too crazy in this last module because this is meant to be more of an introduction into the kind of field of reinforcement learning than anything else but cue learning is the most basic way to implement reinforcement learning at least that. I have discovered and essentially what cue learning is and I don't actually really know why they call it Q although I should probably know that he's creating some kind of table or matrix likes data structure it's going to contain. As the what is it I guess the rows every single state and as the columns every single action that could be taken in all of those different states so for an example here and while do one on kind of the white board later on if we can get there. 

But here we could see that this is kind of my cue table and what I'm saying is that we have a 1 a 2 a 3 a 4 as all the possible actions that can be performed in any given state and we have three states denoted. By the fact that we have three rows and the numbers in this this table with this cube what do they call it Q matrix cube table whatever you want to call it the numbers that are present here represent what the predicted reward will be given that we take an action. Whatever this action is in this state so I'm not sure if this is making sense to you guys but essentially if we're saying that row 0 is state 0 action to a to this value tells us what reward we should expect to get if we take this action. 

While we're in this state that's what that is trying to tell us that's what that means same thing here in you know state two we can see that the optimal action to take would be action two because that has the highest reward for this state. And that's what this table is that we're gonna try to generate with this technique called q-learning a table that can tell us given any state with the predicted reward will be for any action that we take and we're gonna generate this table by exploring the environment many different times and updating these values according to what we kind of see are what the agencies in the environment. And the rewards that receives for any given action in any given state and we'll talk about how we're gonna update that later but this is the basic premise so that is kind of cute learning I'm gonna hop on the whiteboard now. And we'll do a more in-depth example but then we're gonna talk about how we actually learn this cue table that I just discussed.

