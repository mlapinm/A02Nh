### Natural Language Processing With RNNs

Where this breaks apart on these large vocabularies. And that's why I'm going to introduce us now to another concept called word embeddings. Now what word embeddings does is essentially try to find a way to represent words that are similar using very similar numbers. And in fact what a word embedding is actually gonna do I'll talk about this more in detail as we go on is classify or translate every single one of our words into a vector. 

And that vector is gonna have some you know n amount of dimensions usually we're gonna use something like 64 maybe 100 dimensions for each vector. And every single component of that vector will kind of tell us what group it belongs to or how similar it is to other words. So let me give you an idea what I mean so we're gonna create something called the word embeddings. Now don't ask why it's called embeddings i don't know the exact reason. But i believe it's to have has to do something with the fact that they're vectors. And let's just say we have a 3d plane like this. So we've already kind of looked at what vectors are before. 

So I'll skip over explaining them and what we're gonna do is take some word. So let's say we have the word good and instead of picking some integer to represent it. We're gonna pick some vector which means we're gonna draw some vector in this 3d space. Actually let's make this a different color. Let's make this vector say red like this. And this vector represents this word good and in this case we'll say we have X 1 X 2 X 3 is our dimensions which means that every single word in our data set will be represented by three coordinates so one vector with three different dimensions. Where we have X 1 X 2 and X 3 and our hope is that by using this word embeddings layer. 

And we'll talk about how it accomplishes this in a second is that we can have vectors that represent very similar words being very similar. Which means that you know if we have the vector good. Here we would hope the vector happy from our previous example right would be a vector that points in a similar direction to it. That is kind of a similar looking thing where the angle between these two vectors right. And maybe I'll draw it here so we can see is small. So that we know that these words are similar. And then we would hope that if we had a word that was much different maybe say like the word bad. 

That that would point in a different direction the vector that represents it. And that that would tell our model because the angle between these two vectors are so big that these are very different words. Right now in theory does the embedding work layer work like this you know not always. But this is what it's trying to do is essentially pick some representation in a vector form for each word. And then these vectors we hope if they're similar words are going to be pointing in a very similar direction. And that's kind of the best explanation of a word embed layer. I can give you now how do we do this. 

Though how do we actually you know go from word to vector and have that be meaningful. Well this is actually what we call a lair so word embeddings is actually a lair. And it's something we're going to add to our model. And that means that this actually learns the embeddings for our words and the way it does that is by trying to kind of pick out context in the sentence and determine based on where a word is in a sentence kind of what it means and that encodes it. Doing that now I know that's kind of a rough explanation to give to you guys. I don't want to go too far into word embeddings in terms of the math. 

Because I don't want to get you know waste our time or get too complicated if we don't need to. But just understand that our word embeddings are actually trained and that the model actually learns these word embeddings as it goes. And we hope that by the time it's looked at enough training data it's determined really good ways to represent all of our different words so that they make sense to our model in the further layers. And we can use pre trained word embedding layers if we like just like we use that pre trained convolutional base in the previous section. 
And we might actually end up doing that actually probably not in this tutorial but it is something to consider. That you can't do that so that's how word embeddings work this is how we encode textual data and this is why it's so important that we kind of consider the way that we pass information to our neural network because it makes a huge difference.

All right so I'm sure a lot of you were looking at the previous example. I did and you saw the fact that what I did was completely remove the idea of kind of sequence or ordering of words. Right and what I did was just throw I being in a bank and I said all right we're just gonna keep track of the fact that we have you know three ace or we have four does or seven. Tim's right and we're gonna just gonna lose the fact that you know words come after one each other.

We're gonna lose their ordering in the sentence. And that's how we're gonna encode it. And I'm sure a lot of you were saying well why don't we just not lose the ordering of those words we'll just encode every single word with an integer and just leave it in its space where it would have been in the original string. Okay good idea so what you're telling me to do is something like this. You know Tim is here will be our sentence let's say we encode the word Tim with zero is as one here's two and then that means our translation goes zero one two. 

And that means right if we have a translation say like two one zero even though these use the exact same number of words and exact same representation for all these words. Well this is a different sentence and our model should be able to tell that because these words come in a different order. And to you good point if you made that point. But I'm gonna discuss where this falls apart as well and why we're not gonna use this method so although this does solve the problem I talked about previously. Where we're going to kind of lose out on the context of a word there's still is a lot of issues with this. And they come especially when you're dealing with very large vocabularies. 

Now let's take an example where we actually have a vocabulary of say a hundred thousand words and we know that that means. We're gonna have to have a hundred thousand unique mappings from words to integers. So let's say our mappings are something like this one maps to the string happy the word happy right two maps to sad and let's say that the string a hundred thousand are the number hundred thousand maps to the word. I don't know let's say good. Now we know as humans by kind of just thinking about let's consider the fact that we're gonna try to classify sentences as a positive or negative. 

So sentiment analysis that the words happy and good in that regard you know sentiment analysis are probably pretty similar words. Right and then if we were going to group these words we'd probably put them in a similar group we'd classify them as similar words. We could probably interchange them in a sentence and it wouldn't change the meaning a whole ton. I mean it might but you might not as well. And that we could say these are kind of similar. But our model or our encoder right whatever we're doing to translate our text into integers here has decided that a hundred thousand is gonna represent good and one is gonna represent happy. 

And well there's an issue with that because that means when we pass in something like one or a hundred thousand to our model it's gonna have a very difficult time determining the fact that one and a hundred thousand although they're 99999 connect units apart are actually very similar words. And that's the issue we get into when we do something like this is that the numbers we decide to pick to represent each word are very important. And we don't really have a way of being able to look at words group them and saying. Okay well we need to put all of the happy words in the range like 0 to 100 all of the like adjectives in this range. We don't really have a way to do that. 

And this gets even harder for our model when we have these arbitrary mappings right and then we have something like 2 in between where 2 is very close to 1. Right yet these words are complete opposites. In fact I'd say they're probably polar opposites our model trying to learn that the difference between 1 & 2 is actually way larger than the difference between one and a hundred thousand is gonna be very difficult. And say it's even able to do that as soon as we throw in the mapping 900 right the ninety nine thousand nine hundred. We put that as bad. Well now it gets even more difficult because it's now like okay. What the range is this big. 

Then that means these words are actually very similar but then you throw another word in here. Like this and it messes up the entire system. So that's kind of what I wanted to show. 











